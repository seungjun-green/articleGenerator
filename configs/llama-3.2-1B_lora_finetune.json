{
    "base_model_name": "meta-llama/Llama-3.2-1B",
    "lora_rank": 16,
    "lora_alpha": 16,
    "learning_rate": 1e-6,
    "batch_size": 8,
    "max_seq_length": 512,
    "num_epochs": 3,
    "output_dir": "./fine_tuned_checkpoints",
    "log_steps": 1000,
    "device": "cuda",
    "use_fp16": false,
    "warmup_ratio": 0,
    "train_file_path": "",
    "dev_file_path": ""
}